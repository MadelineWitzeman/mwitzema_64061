{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BA 64061 Assignment 2 Summary/Report"
      ],
      "metadata": {
        "id": "UeXlgNwZe465"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Madeline Witzeman"
      ],
      "metadata": {
        "id": "pq9Ue0v5l_xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "2qOYKfqr-Ouh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_models = [['From Scratch', 1000, 'No', 'No', '70.0% -75.0%', '65.0% - 72.0%'], ['From Scratch', 1000, 'Yes', 'Yes', '80.0% - 85.0%', '79.0% - 83.0%'], ['From Scratch', 3000, 'No', 'No', '78.0% - 82.0%', '78.0% - 82.0%'], ['From Scratch', 3000, 'Yes', 'Yes', '90.0% - 92.0%', '89.0% - 92.0%'], ['From Scratch', 5000, 'Yes', 'Yes', '91.0% - 94.0%', '90.0% - 92.0%'], ['From Scratch', 2000, 'Yes', 'Yes', '87.0% - 91.0%', '90.0% - 92.0%'], ['Pretrain - Feature', 1000, 'Yes', 'No', '~98.0%', 'NA'], ['Pretrain - Feature', 1000, 'Yes', 'Yes', '~98.0%', '96.0% - 98.0%'], ['Pretrain - Feature', 3000, 'Yes', 'Yes', '97.0% - 98.5%', '97.0% - 99.0%'], ['Pretrain - Feature', 5000, 'Yes', 'Yes', '97.5% - 98.5%', '97.0% - 98.5%'], ['Pretrain - Feature', 2000, 'Yes', 'Yes', '97.0% - 98.0%', '97.0% - 98.5%'], ['Pretrain - Fine-tune', 3000, 'Yes', 'Yes', '97.5% - 98.3%', '97.0% - 98.0%']]"
      ],
      "metadata": {
        "id": "IxEmcxNsVrmJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.DataFrame(data_models, index=[1,2,3,4,5,6,7,8,9,10,11,12], columns=['Network Type', 'Training Sample Size', 'Dropout Used?', 'Data Augment Used?', 'Validation Accuracy', 'Test Accuracy'])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKwuP-VIYCHB",
        "outputId": "761e3ae4-23ba-4cff-ce5c-c44abbb6eb4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Network Type  Training Sample Size Dropout Used?  \\\n",
            "1           From Scratch                  1000            No   \n",
            "2           From Scratch                  1000           Yes   \n",
            "3           From Scratch                  3000            No   \n",
            "4           From Scratch                  3000           Yes   \n",
            "5           From Scratch                  5000           Yes   \n",
            "6           From Scratch                  2000           Yes   \n",
            "7     Pretrain - Feature                  1000           Yes   \n",
            "8     Pretrain - Feature                  1000           Yes   \n",
            "9     Pretrain - Feature                  3000           Yes   \n",
            "10    Pretrain - Feature                  5000           Yes   \n",
            "11    Pretrain - Feature                  2000           Yes   \n",
            "12  Pretrain - Fine-tune                  3000           Yes   \n",
            "\n",
            "   Data Augment Used? Validation Accuracy  Test Accuracy  \n",
            "1                  No        70.0% -75.0%  65.0% - 72.0%  \n",
            "2                 Yes       80.0% - 85.0%  79.0% - 83.0%  \n",
            "3                  No       78.0% - 82.0%  78.0% - 82.0%  \n",
            "4                 Yes       90.0% - 92.0%  89.0% - 92.0%  \n",
            "5                 Yes       91.0% - 94.0%  90.0% - 92.0%  \n",
            "6                 Yes       87.0% - 91.0%  90.0% - 92.0%  \n",
            "7                  No              ~98.0%             NA  \n",
            "8                 Yes              ~98.0%  96.0% - 98.0%  \n",
            "9                 Yes       97.0% - 98.5%  97.0% - 99.0%  \n",
            "10                Yes       97.5% - 98.5%  97.0% - 98.5%  \n",
            "11                Yes       97.0% - 98.0%  97.0% - 98.5%  \n",
            "12                Yes       97.5% - 98.3%  97.0% - 98.0%  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I began my analysis by starting with a simple convolutional network that I trained from scratch using 1,000 images for training, 500 for validation, and 500 for testing. In this initial network, I didn't utilize any dropout or data augmentation so I had an initial baseline to work with. The plots for the model indicated that the model was overfitting. Validation accuracy only hit ~70%-75% at most, and the validation loss increased as the number of epochs continued to grow beyond 10. Additionally, the test accuracy was only ~70%. To address the overfitting in the initial model, I employed data augmentation and dropout to see how it affected the validation and test accuracies. After including data augmentation and droupout in the initial model, the validation accuracy increased to ~80-85% and the test accuracy increased significantly to ~79-83%. Using data augmentation and dropout significantly improved model performance."
      ],
      "metadata": {
        "id": "7ZKdHP2Se_Rq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51649nBL3BXx"
      },
      "source": [
        "My next approach involved varying the training sample size while keeping the validation and test sample size constant. I first increased the training sample from 1,000 images to 3,000 images while using no dropout or data augmentation. The plots indicated that increasing the training sample size from 1,000 images to 3,000 images improved performance: validation accuracy hit around 78%-82%, and the test accuracy was ~78%-82%. However, there appeared to be overfitting again. I  wanted to see if I could improve model performance and reduce overfitting by employing data augmentation and dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU0_19fDvbeK"
      },
      "source": [
        "After both increasing the training sample size to 3,000 images and using data augmentation and dropout, model performance improved significantly: the validation accuracy was ~90%-92% and the test accuracy was ~89%-92%. Since the initial models for a training sample size of 1,000 images and 3,000 images were indicating overfitting, I decided to automatically utilize data augmentation and dropout moving forward when generating new models and assessing performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQySX4A2r8J"
      },
      "source": [
        "My next appraoch involved increasing the training sample size again to 5,000 images, which slightly increased the validation accuracy to ~91%-94% and kept the test accuracy around ~90%-92%. However, there were some odd/concerning trends depicted on the training and validation accuracy and loss plots. Both training and validation accuracy started dropping after ~35 epochs. Having the training accuracy drop as the model continues to train is the opposite of what I'd expect. Based on my research, it seems this may be related to using the rmsprop optimizer or the training rate, but I'm not entirely sure. Additionally, the validation accuracy was actually above the training accuracy across several epochs. I'm also not sure the exact reason for this, but am wondering if the validation dataset may be too small compared to the larger training dataset and therefore this is something happening by chance. Lastly, it's interesting that both validation and test loss are low throughout training, with the exceptions of a few data points where the validation loss spikes. Given the odd trends displayed on the training and validation accuracy and loss plots, I had concerns utilizing this model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exiX72CpKxIp"
      },
      "source": [
        "Additionally, I also tried decreasing the training sample size to 2,000 images which resulted in a validation accuracy of ~87%-91% and a test accuracy of ~90%-92%. These are very similar results to the model with a training sample of 3,000 images (and data augmentation + dropout), but the model using 3,000 images for training appeared to be slightly better."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After making several adjustments while training a network from scratch, I repeated the steps above using a pretrained network. I chose to utilize the VGG16 convolutional base since it was trained using animal pictures (several cats and dogs) from ImageNet. I started with a simple pretrained network that employed dropout but no data augmentation. Using a pretrained network with dropout (and no data augmentation) noticeably improved performance: the validation accuracy increased to ~98%. The test accuracy couldn't be computed yet because the shape of the test dataset wasn't the same as the pretrained network shape. I next decided to add data augmentation to the pretrained network to see how it would affect performance. Using a pretrained network with both dropout and data augmentation resulted in a validation accuracy of ~98% and a test accuracy of ~96%-98%. This was a significant improvement in performance over any of the networks trained from scratch. Given the increase in model performance, I chose to utlize dropout + data augmentation in the pretrained networks moving forward."
      ],
      "metadata": {
        "id": "ww4h6mO_iqgz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSOVees-03VD"
      },
      "source": [
        "Similar to the steps above used in training a network from scratch, I next increased the training sample size to 3,000 images and 5,000 images, and also decreased the training sample size to 2,000 images. Increasing the training sample size from 1,000 images to 3,000 images increased validation accuracy to ~97.0%-98.5% and test accuracy to ~97.0%-99.0%. This was the model with the best performance so far.\n",
        "\n",
        "Increasing the training sample size to 5,000 images kept validation accuracy around ~97.5%-98.5% and test accuracy to ~97.0%-98.5%. However, similar to when I trained the model from scratch using 5,000 images, there were strange trends displayed on the training and validation accuracy and loss plots: validation accuracy was consistently higher than training accuracy, yet both training and validation loss were very low. Given these strange trends, I believe increasing the training sample to 5,000 images (or more) isn't the best approach. Decreasing the training sample size to 2,000 images produced a validation accuracy of ~97.0%-98.0% and a test accuracy of ~97.0%-98.5%. This was overall slightly worse than the pretrained model that used a training sample size of 3,000 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrtIdghm5tNc"
      },
      "source": [
        "Lastly, since I had been using feature extraction of pretrained models, I wanted to also see if taking the approach of fine-tuning a pretrained model improved performance. I chose to work with a training sample size of 3,000 images since that produced the best results when both training from scratch and using feature extraction of a pretrained model. Fine-tuning the pre-trained model using a training sample size of 3,000 images resulted in a validation accuracy of ~97.5%-98.3% and a test accuracy of ~97.0%-98.0%. The training and validation accuracy plot depicted somewhat erratic validation accuracy that frequently dropped and increased. Additionally, the training and validation loss plot also depicted a concerning trend: the validation loss was consistently above 1 and even spiked above 1.5. Given these patterns, fine-tuning the model didn't improve performance, although there are more parameters that would need to be adjusted before entirely ruling out the fine-tuning approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziLFBYsO_LBQ"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6qql3ZE_Mce"
      },
      "source": [
        "## In conclusion, the pretrained model using feature extraction and a training sample size of 3,000 images overall performed the best. It appears that increasing the training sample size, up to a certain point, increases the model performance, whether a network is being trained from scratch or a pretrained network is being utilized. The threshold seems to be 3,000 images when keeping the validation and test datasets at 500 images each. The models that used the smallest training sample size (1,000 images) had the worst performance, which implies that the training sample needs to be large enough in order to promote effective learning.\n",
        "\n",
        "## Additionally, utilizing a pretrained model improved model performance over training a model from scratch. This makes sense given the pretrained model I worked from was trained on a dataset of animal pictures that included several cat and dog pictures. Lastly, utilizing both dropout and data augmentation helped reduce overfitting and improved model performance across both networks trained from scratch and pretrained networks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --execute --to pdf \"/content/drive/MyDrive/Colab Notebooks/BA 64061 Assignment 2 Summary Report Madeline Witzeman.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjJIgZz0zh2o",
        "outputId": "712e8492-8c09-4974-8b2d-5a5b94d61db2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/BA 64061 Assignment 2 Summary Report Madeline Witzeman.ipynb to pdf\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "[NbConvertApp] ERROR | unhandled iopub msg: colab_request\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbclient/client.py\", line 606, in setup_kernel\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/preprocessors/execute.py\", line 89, in preprocess\n",
            "    self.preprocess_cell(cell, resources, index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/preprocessors/execute.py\", line 110, in preprocess_cell\n",
            "    cell = self.execute_cell(cell, index, store_history=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n",
            "    return loop.run_until_complete(inner)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 636, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1871, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 469, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter-nbconvert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/application.py\", line 283, in launch_instance\n",
            "    super().launch_instance(argv=argv, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 423, in start\n",
            "    self.convert_notebooks()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 597, in convert_notebooks\n",
            "    self.convert_single_notebook(notebook_filename)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 560, in convert_single_notebook\n",
            "    output, resources = self.export_single_notebook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/nbconvertapp.py\", line 488, in export_single_notebook\n",
            "    output, resources = self.exporter.from_filename(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 189, in from_filename\n",
            "    return self.from_file(f, resources=resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 206, in from_file\n",
            "    return self.from_notebook_node(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/pdf.py\", line 181, in from_notebook_node\n",
            "    latex, resources = super().from_notebook_node(nb, resources=resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/latex.py\", line 74, in from_notebook_node\n",
            "    return super().from_notebook_node(nb, resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/templateexporter.py\", line 397, in from_notebook_node\n",
            "    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 146, in from_notebook_node\n",
            "    nb_copy, resources = self._preprocess(nb_copy, resources)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/exporters/exporter.py\", line 335, in _preprocess\n",
            "    nbc, resc = preprocessor(nbc, resc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/preprocessors/base.py\", line 47, in __call__\n",
            "    return self.preprocess(nb, resources)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbconvert/preprocessors/execute.py\", line 85, in preprocess\n",
            "    with self.setup_kernel():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nbclient/client.py\", line 609, in setup_kernel\n",
            "    self._cleanup_kernel()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jupyter_core/utils/__init__.py\", line 165, in wrapped\n",
            "    return loop.run_until_complete(inner)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 628, in run_until_complete\n",
            "    future = tasks.ensure_future(future, loop=self)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 615, in ensure_future\n",
            "    return _ensure_future(coro_or_future, loop=loop)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 636, in _ensure_future\n",
            "    return loop.create_task(coro_or_future)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 438, in create_task\n",
            "    task = tasks.Task(coro, loop=self, name=name)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 757, in call_soon\n",
            "    handle = self._call_soon(callback, args, context)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 773, in _call_soon\n",
            "    handle = events.Handle(callback, args, self, context)\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 31, in __init__\n",
            "    def __init__(self, callback, args, loop, context=None):\n",
            "KeyboardInterrupt\n",
            "Task was destroyed but it is pending!\n",
            "task: <Task pending name='Task-32' coro=<NotebookClient._async_cleanup_kernel() running at /usr/local/lib/python3.10/dist-packages/nbclient/client.py:503>>\n",
            "sys:1: RuntimeWarning: coroutine 'NotebookClient._async_cleanup_kernel' was never awaited\n",
            "[ColabKernelApp] WARNING | Parent appears to have exited, shutting down.\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5dsC_i_K2EY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c89d17-65a6-4a62-fc27-ba98c1fc30c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}