# -*- coding: utf-8 -*-
"""BA 64061 Assignment 2 Madeline Witzeman.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F_EmbzO3HYx5Lxukn9VkIqYl0vaWCeOD

# Assignment 2: Convolution
# BA 64061-003
# Madeline Witzeman

# First step: Loading the Cats and Dogs dataset
"""

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c dogs-vs-cats

!unzip -qq dogs-vs-cats.zip

!unzip -qq train.zip

"""## Copying images to training, validation, and test directories"""

import os, shutil, pathlib

original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")

def make_subset(subset_name, start_index, end_index):
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train", start_index=667, end_index=1667)
make_subset("validation", start_index=1668, end_index=2168)
make_subset("test", start_index=2169, end_index=2669)

"""# Next Step: Building the Initial Model for Problem #1 (Training Model from Scratch)

## Setting up small initial convnet for dogs vs. cats classification
"""

from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(180, 180, 3))
x = layers.Rescaling(1./255)(inputs)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.summary()

"""## Configuring the model for training"""

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

"""I'm initially establishing a model with an alternating stack of Conv2D and MaxPooling2D layers -- the model needs to also reduce the size of the feature maps enough prior to the Flatten layer. Additionally, since this is a binary-classification problem, I ended the model with a single Dense layer (size of '1') with sigmoid activation. Lastly, I utilized the RMPprop optimizer since it's a standard choice and binary crossentropy as the loss function since the final layer is a single sigmoid unit.

## Data Preprocessing: Using image_dataset_from_directory to read images
"""

from tensorflow.keras.utils import image_dataset_from_directory

train_dataset = image_dataset_from_directory(
    new_base_dir / "train",
    image_size=(180, 180),
    batch_size=32)
validation_dataset = image_dataset_from_directory(
    new_base_dir / "validation",
    image_size=(180, 180),
    batch_size=32)
test_dataset = image_dataset_from_directory(
    new_base_dir / "test",
    image_size=(180, 180),
    batch_size=32)

"""Checking the shapes of data batches and labels:"""

for data_batch, labels_batch in train_dataset:
    print("data batch shape:", data_batch.shape)
    print("labels batch shape:", labels_batch.shape)
    break

"""The data needed to be formatted into tensors prior to being fed into the convnet.

## Fitting the model, saving only the best model according to the validation loss after each epoch
"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=30,
    validation_data=validation_dataset,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model("convnet_from_scratch.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")

"""The plots above indicate that the current model is overfitting. Validation accuracy only hits ~70%-75% at most, and the validation loss increases as the number of epochs continues to grow beyond 10. Additionally, the test accuracy is only ~70%. (Used average based on 3 runs to establish solid baseline to compare against -- accuracy metrics will vary some due to stochastic learning of the model)

-Run 1: 71.1%
-Run 2: 65.7%
-Run 3: 72.2%

To address the overfitting in the current model, I'm going to employ data augmentation and dropout and see how it affects the validation and test accuracies.

# Problem #1 Continued: Utilizing Data Augmentation and Dropout to Reduce Overfitting and Improve Performance of Initial Model

## Defining data augmentation stage to apply in convnet model
"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

"""## Defining a new convnet that includes image augmentation and dropout"""

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

"""Since the initial training sample size is relatively small, the model is overfitting early in training. Data augmentation helps mitigate the effects of a small training sample size by essentially generating more training data: it allows the model to learn more aspects of the existing data. The input data will now be randomly flipped horizontally, randomly rotated -36 degrees to +36 degrees, and randomly zoomed in/out somewhere within the range of -20% to +20%. Utilizing dropout also helps mitigate overfitting, as just data augmentation alone may not be enough.

## Training new convnet (data augmentation + dropout)
"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch_with_augmentation.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=100,
    validation_data=validation_dataset,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "convnet_from_scratch_with_augmentation.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")

"""After including data augmentation and droupout in the initial model, the validation accuracy increased to ~80-85% at most and the test accuracy increased significantly to ~79-83%. (Again, accuracy metrics will vary some due to stochastic learning of the model).

Using data augmentation and dropout significantly improved model performance.

# Problem #2: Increasing Training Sample Size and Training New Model from Scratch

## Increasing training sample size from 1,000 to 3,000 images & copying images to training, validation, and test directories
"""

import os, shutil, pathlib

original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")

def make_subset(subset_name, start_index, end_index):
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train2", start_index=667, end_index=3667)
make_subset("validation2", start_index=3668, end_index=4168)
make_subset("test2", start_index=4169, end_index=4669)

"""# Building the Initial Model for Problem #2 (Training Model from Scratch)

## Setting up initial convnet based on larger training sample
"""

from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(180, 180, 3))
x = layers.Rescaling(1./255)(inputs)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

model.summary()

"""## Data Preprocessing: Using image_dataset_from_directory to read images"""

from tensorflow.keras.utils import image_dataset_from_directory

train_dataset2 = image_dataset_from_directory(
    new_base_dir / "train2",
    image_size=(180, 180),
    batch_size=32)
validation_dataset2 = image_dataset_from_directory(
    new_base_dir / "validation2",
    image_size=(180, 180),
    batch_size=32)
test_dataset2 = image_dataset_from_directory(
    new_base_dir / "test2",
    image_size=(180, 180),
    batch_size=32)

for data_batch, labels_batch in train_dataset2:
    print("data batch shape:", data_batch.shape)
    print("labels batch shape:", labels_batch.shape)
    break

"""## Fitting the model, saving only the best model according to the validation loss after each epoch"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch2.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset2,
    epochs=30,
    validation_data=validation_dataset2,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model("convnet_from_scratch2.keras")
test_loss, test_acc = test_model.evaluate(test_dataset2)
print(f"Test accuracy: {test_acc:.3f}")

"""The plots above indicate that increasing the training sample size from 1,000 images to 3,000 images improved performance: validation accuracy now hits around 78%-82%, and the test accuracy is also ~78%-82%. (Accuracy metrics will vary some due to stochastic learning of the model).

However, there appears to be overfitting again. I'm going to see if I can improve model performance and reduce overfitting by employing data augmentation and dropout.

# Problem #2 Continued: Adding Data Augmentation and Dropout

## Defining data augmentation stage to apply in convnet model
"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

"""## Defining a new convnet that includes image augmentation and dropout"""

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

"""## Training new convnet (data augmentation + dropout)"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch_with_augmentation2.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset2,
    epochs=100,
    validation_data=validation_dataset2,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "convnet_from_scratch_with_augmentation2.keras")
test_loss, test_acc = test_model.evaluate(test_dataset2)
print(f"Test accuracy: {test_acc:.3f}")

"""After both increasing the training sample size to 3,000 images and using data augmentation and dropout, model performance improved significantly: the validation accuracy is ~90%-92% at most and the test accuracy is ~89%-92% (with some variation). One thing to note -- there is an interesting pattern displayed on the training and validation accuracy plot where the validation accuracy closely follows the training accuracy and even surpasses it in some instances.

Since the initial models for a training sample size of 1,000 images and 3,000 images were indicating overfitting, I'm going to automatically utilize data augmentation and dropout moving forward when generating new models and assessing performance.

# Problem #3: Adjusting Training Sample Size Again and Training New Models from Scratch to Achieve Best Performance

## Increasing Training Sample Size from 3,000 to 5,000 images & copying images to training, validation, and test directories
"""

import os, shutil, pathlib

original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")

def make_subset(subset_name, start_index, end_index):
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train3", start_index=667, end_index=5667)
make_subset("validation3", start_index=5668, end_index=6168)
make_subset("test3", start_index=6169, end_index=6669)

"""## Data Preprocessing: Using image_dataset_from_directory to read images"""

from tensorflow.keras.utils import image_dataset_from_directory

train_dataset3 = image_dataset_from_directory(
    new_base_dir / "train3",
    image_size=(180, 180),
    batch_size=32)
validation_dataset3 = image_dataset_from_directory(
    new_base_dir / "validation3",
    image_size=(180, 180),
    batch_size=32)
test_dataset3 = image_dataset_from_directory(
    new_base_dir / "test3",
    image_size=(180, 180),
    batch_size=32)

for data_batch, labels_batch in train_dataset3:
    print("data batch shape:", data_batch.shape)
    print("labels batch shape:", labels_batch.shape)
    break

"""## Defining data augmentation stage to apply in convnet model"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

"""## Defining a new convnet that includes image augmentation and dropout"""

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

"""## Training new convnet (data augmentation + dropout + larger training sample)"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch_with_augmentation3.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset3,
    epochs=100,
    validation_data=validation_dataset3,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "convnet_from_scratch_with_augmentation3.keras")
test_loss, test_acc = test_model.evaluate(test_dataset3)
print(f"Test accuracy: {test_acc:.3f}")

"""Increasing the training sample size to 5,000 images slightly increases the validation accuracy to ~91%-94% at most and keeps the test accuracy to ~90%-92% (with some variation).

However, there are some odd/concerning trends depicted on the training and validation accuracy and loss plots. Both training and validation accuracy start dropping after ~35 epochs. Having the training accuracy drop as the model continues to train is the opposite of what I'd expect. Based on my research, it seems this may be related to using the rmsprop optimizer or the training rate, but I'm not entirely sure. Additionally, the validation accuracy is actually above the training accuracy across several epochs. I'm also not sure the exact reason for this, but am wondering if the validation dataset may be too small compared to the larger training dataset and therefore this is something happening by chance. Lastly, it's interesting that both validation and test loss are low throughout training, with the exceptions of a few data points where the validation loss spikes.

Given the odd trends displayed on the training and validation accuracy and loss plots, I am considering the model that used 3,000 training images and image augmentation + dropout to be the best model so far.

# Problem #3 Continued: Decreasing the training sample size

## Decreasing Training Sample Size to 2,000 images & copying images to training, validation, and test directories

Since the training sample size of 3,000 images achieved better perfomance than a training sample size of 1,000, I'm going to see if a training sample size of 2,000 images is a "sweet spot" and somehow better than a training sample size of 3,000 or 5,000.
"""

import os, shutil, pathlib

original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")

def make_subset(subset_name, start_index, end_index):
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train4", start_index=667, end_index=2667)
make_subset("validation4", start_index=2668, end_index=3168)
make_subset("test4", start_index=3169, end_index=3669)

"""## Data Preprocessing: Using image_dataset_from_directory to read images"""

from tensorflow.keras.utils import image_dataset_from_directory

train_dataset4 = image_dataset_from_directory(
    new_base_dir / "train4",
    image_size=(180, 180),
    batch_size=32)
validation_dataset4 = image_dataset_from_directory(
    new_base_dir / "validation4",
    image_size=(180, 180),
    batch_size=32)
test_dataset4 = image_dataset_from_directory(
    new_base_dir / "test4",
    image_size=(180, 180),
    batch_size=32)

for data_batch, labels_batch in train_dataset4:
    print("data batch shape:", data_batch.shape)
    print("labels batch shape:", labels_batch.shape)
    break

"""## Defining data augmentation stage to apply in convnet model"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

"""## Defining a new convnet that includes image augmentation and dropout"""

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=2)(x)
x = layers.Conv2D(filters=256, kernel_size=3, activation="relu")(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

"""## Training new convnet (data augmentation + dropout + larger training sample)"""

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="convnet_from_scratch_with_augmentation4.keras",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset4,
    epochs=100,
    validation_data=validation_dataset4,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "convnet_from_scratch_with_augmentation4.keras")
test_loss, test_acc = test_model.evaluate(test_dataset4)
print(f"Test accuracy: {test_acc:.3f}")

"""Using a training sample size of 2,000 images resulted in a validation accuracy of ~87%-91% at best and a test accuracy of ~90%-92%. This is very similar to the model with a training sample of 3,000 images (and data augmentation + dropout), but the model using 3,000 images for training appears to be slightly better.

# Problem #4: Repeat Problems 1 - 3 using a Pretrained Network

## Establishing the VGG16 convolutional base
"""

conv_base = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False,
    input_shape=(180, 180, 3))

conv_base.summary()

"""I chose to utilize the VGG16 convolutional base since it was trained using animal pictures (several cats and dogs) from ImageNet.

## Extracting the VGG16 features and corresponding labels
"""

import numpy as np

def get_features_and_labels(dataset):
    all_features = []
    all_labels = []
    for images, labels in dataset:
        preprocessed_images = keras.applications.vgg16.preprocess_input(images)
        features = conv_base.predict(preprocessed_images)
        all_features.append(features)
        all_labels.append(labels)
    return np.concatenate(all_features), np.concatenate(all_labels)

train_features, train_labels =  get_features_and_labels(train_dataset)
val_features, val_labels =  get_features_and_labels(validation_dataset)
test_features, test_labels =  get_features_and_labels(test_dataset)

train_features.shape

"""## Defining and training the densely connected classifier, starting with training sample of 1,000, validation sample of 500, and test sample of 500 + dropout for regularization"""

inputs = keras.Input(shape=(5, 5, 512))
x = layers.Flatten()(inputs)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
      filepath="feature_extraction.keras",
      save_best_only=True,
      monitor="val_loss")
]
history = model.fit(
    train_features, train_labels,
    epochs=20,
    validation_data=(val_features, val_labels),
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""Using a pretrained network with dropout (and no data augmentation) noticeably improves performance: the validation accuracy increased to ~98%. The test accuracy can't be computed yet because the shape of the test dataset isn't the same as the pretrained network shape.

# Problem #4 Continued: Utilizing Data Augmentation in Pretrained Network to Reduce Overfitting and Improve Performance of Initial Model (Still using Feature Extraction)

## Establishing and freezing the VGG16 convolutional base
"""

conv_base  = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False)
conv_base.trainable = False

"""## Printing the list of trainable weights before and after freezing"""

conv_base.trainable = True
print("This is the number of trainable weights "
      "before freezing the conv base:", len(conv_base.trainable_weights))

conv_base.trainable = False
print("This is the number of trainable weights "
      "after freezing the conv base:", len(conv_base.trainable_weights))

"""## Adding a data augmentation stage and a classifier to the initial convolutional base"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = keras.applications.vgg16.preprocess_input(x)
x = conv_base(x)
x = layers.Flatten()(x)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="feature_extraction_with_data_augmentation",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset,
    epochs=50,
    validation_data=validation_dataset,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "feature_extraction_with_data_augmentation")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"Test accuracy: {test_acc:.3f}")

"""Using a pretrained network with both dropout and data augmentation results in a validation accuracy of ~98% and a test accuracy of ~96%-98%. This is a significant improvement in performance over any of the networks trained from scratch in problems 1 - 3. Given this increase in model performance, I'm going to utlize dropout + data augmentation in the pretrained networks moving forward.

# Problem #4 Cont: Increasing Training Sample Size to 3,000 images (Still Using Feature Extraction)

## Establishing and freezing the VGG16 convolutional base
"""

conv_base  = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False)
conv_base.trainable = False

"""## Adding a data augmentation stage and a classifier to the initial convolutional base; reference correct training/validation/test datasets"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = keras.applications.vgg16.preprocess_input(x)
x = conv_base(x)
x = layers.Flatten()(x)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="feature_extraction_with_data_augmentation2",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset2,
    epochs=50,
    validation_data=validation_dataset2,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "feature_extraction_with_data_augmentation2")
test_loss, test_acc = test_model.evaluate(test_dataset2)
print(f"Test accuracy: {test_acc:.3f}")

"""Increasing the training sample size from 1,000 images to 3,000 images increased validation accuracy to ~97.0%-98.5% at most and test accuracy to ~97.0%-99.0%. This is the model with the best performance so far.

# Problem #4 Cont: Increasing Training Sample Size to 5,000 images (Still Using Feature Extraction)

## Establishing and freezing the VGG16 convolutional base
"""

conv_base  = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False)
conv_base.trainable = False

"""## Adding a data augmentation stage and a classifier to the initial convolutional base; reference correct training/validation/test datasets"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = keras.applications.vgg16.preprocess_input(x)
x = conv_base(x)
x = layers.Flatten()(x)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="feature_extraction_with_data_augmentation3",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset3,
    epochs=50,
    validation_data=validation_dataset3,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "feature_extraction_with_data_augmentation3")
test_loss, test_acc = test_model.evaluate(test_dataset3)
print(f"Test accuracy: {test_acc:.3f}")

"""Increasing the training sample size to 5,000 images kept validation accuracy around ~97.5%-98.5% at most and test accuracy to ~97.0%-98.5%. However, similar to when I trained the model from scratch using 5,000 images, there are strange trends displayed on the training and validation accuracy and loss plots: validation accuracy is consistently higher than training accuracy, and both training and validation loss are very low. Given these strange trends, I believe increasing the training sample to 5,000 images (or more) isn't the best approach.

# Problem #4 Cont: Decreasing Training Sample Size to 2,000 images (Still Using Feature Extraction)

## Establishing and freezing the VGG16 convolutional base
"""

conv_base  = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False)
conv_base.trainable = False

"""## Adding a data augmentation stage and a classifier to the initial convolutional base; reference correct training/validation/test datasets"""

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

inputs = keras.Input(shape=(180, 180, 3))
x = data_augmentation(inputs)
x = keras.applications.vgg16.preprocess_input(x)
x = conv_base(x)
x = layers.Flatten()(x)
x = layers.Dense(256)(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="feature_extraction_with_data_augmentation4",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset4,
    epochs=50,
    validation_data=validation_dataset4,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

test_model = keras.models.load_model(
    "feature_extraction_with_data_augmentation4")
test_loss, test_acc = test_model.evaluate(test_dataset4)
print(f"Test accuracy: {test_acc:.3f}")

"""Decreasing the training sample size to 2,000 images produces a validation accuracy of ~97.0%-98.0% at most and a test accuracy of ~97.0% - 98.5%. This is overall slightly worse than the pretrained model that used a training sample size of 3,000 images.

# Problem #4 Cont: Fine-Tuning a Pretrained Model using a Training Sample Size of 3,000 images

Since I've been using feature extraction of pretrained models up until now, I'm going to also see if taking the approach of fine-tuning a pretrained model improves performance. I'm going to work with a training sample size of 3,000 images since that produced the best results when both training from scratch and using feature extraction of a pretrained model.

## Freezing all layers until the fourth from the last
"""

conv_base.trainable = True
for layer in conv_base.layers[:-4]:
    layer.trainable = False

"""## Fine-tuning the model (using training sample size of 3,000)"""

model.compile(loss="binary_crossentropy",
              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),
              metrics=["accuracy"])

callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="fine_tuning",
        save_best_only=True,
        monitor="val_loss")
]
history = model.fit(
    train_dataset2,
    epochs=30,
    validation_data=validation_dataset2,
    callbacks=callbacks)

"""## Displaying curves of loss and accuracy during training"""

import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

"""## Evaluating the accuracy of the model on the test dataset"""

model = keras.models.load_model("fine_tuning")
test_loss, test_acc = model.evaluate(test_dataset2)
print(f"Test accuracy: {test_acc:.3f}")

"""Fine-tuning the pre-trained model using a training sample size of 3,000 images results in a validation accuracy of ~97.5%-98.3% at best and a test accuracy of ~97.0%-98.0%. The training and validation accuracy plot depicts somewhat erratic validation accuracy that frequently drops and increases. Additionally, training accuracy is significantly higher than the validation accuracy. Lastly, the training and validation loss plot also depicts a concerning trend: the validation loss is consistently above 1 and even spikes above 1.5. Given these patterns, fine-tuning the model didn't improve performance, although there are more parameters that would need to be adjusted before entirely ruling out the fine-tuning approach.

# Conclusion
"""

import pandas

data_models = [['From Scratch', 1000, 'No', 'No', '70.0% -75.0%', '65.0% - 72.0%'], ['From Scratch', 1000, 'Yes', 'Yes', '80.0% - 85.0%', '79.0% - 83.0%'], ['From Scratch', 3000, 'No', 'No', '78.0% - 82.0%', '78.0% - 82.0%'], ['From Scratch', 3000, 'Yes', 'Yes', '90.0% - 92.0%', '89.0% - 92.0%'], ['From Scratch', 5000, 'Yes', 'Yes', '91.0% - 94.0%', '90.0% - 92.0%'], ['From Scratch', 2000, 'Yes', 'Yes', '87.0% - 91.0%', '90.0% - 92.0%'], ['Pretrain - Feature', 1000, 'Yes', 'No', '~98.0%', 'NA'], ['Pretrain - Feature', 1000, 'Yes', 'Yes', '~98.0%', '96.0% - 98.0%'], ['Pretrain - Feature', 3000, 'Yes', 'Yes', '97.0% - 98.5%', '97.0% - 99.0%'], ['Pretrain - Feature', 5000, 'Yes', 'Yes', '97.5% - 98.5%', '97.0% - 98.5%'], ['Pretrain - Feature', 2000, 'Yes', 'Yes', '97.0% - 98.0%', '97.0% - 98.5%'], ['Pretrain - Fine-tune', 3000, 'Yes', 'Yes', '97.5% - 98.3%', '97.0% - 98.0%']]

df = pandas.DataFrame(data_models, index=[1,2,3,4,5,6,7,8,9,10,11,12], columns=['Network Type', 'Training Sample Size', 'Dropout Used?', 'Data Augment Used?', 'Validation Accuracy', 'Test Accuracy'])
print(df)

"""## In conclusion, the pretrained model using feature extraction and a training sample size of 3,000 images overall performed the best. It appears that increasing the training sample size, up to a certain point, increases the model performance, whether a network is being trained from scratch or a pretrained network is being utilized. The threshold seems to be 3,000 images when keeping the validation and test datasets at 500 images each. The models that used the smallest training sample size (1,000 images) had the worst performance, which implies that the training sample needs to be large enough in order to promote effective learning.

## Additionally, utilizing a pretrained model improved model performance over training a model from scratch. This makes sense given the pretrained model I worked from was trained on a dataset of animal pictures that included several cat and dog pictures. Lastly, utilizing both dropout and data augmentation helped reduce overfitting and improved model performance across both networks trained from scratch and pretrained networks.
"""